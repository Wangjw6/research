{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【点滴】学习强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Q-Learning Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Learning 方法是强化学习算法家族中的一个经典算法，它有别于目前应用更加广泛的基于策略的强化学习算法，但是是入门强化学习的很好的基础。因此，整个学习路线是：首先弄懂Q-Learning的原理，完成其最基础的实现（look-up table），然后以神经网络为元件实现Q-Learning，再进入policy-based方法的学习，逐渐进入前沿强化学习方法领域。\n",
    "\n",
    "强化学习中包含两种主流算法，基于策略的算法是直接学习如何将一个状态映射为一个动作；基于状态（动作）价值的算法则是学习每个经历状态的效益值，或者状态-动作对的效益值，然后基于该效益值筛选动作。可以看到，尽管两个方法最终都实现同一个目标——为给定状态选择合适的动作，但它们的完成方式有显著的区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 基于Q-Table的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本小节将首先以OpenAI Gym提供的[FrozenLake](https://gym.openai.com/envs/FrozenLake-v0/)环境为研究案例。OpenAI Gym提供了一系列简单的强化学习应用场景，方便人们测试自己的算法。在Frozen Lake中，智能体将被放入一个4\\*4的网格阵，每个网格对应一定的特性："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://miro.medium.com/max/1050/1*MCjDzR-wfMMkS0rPqXSmKw.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">FrozenLake环境示意图</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体在该环境的学习目标是：从起始方块（S）出发，到达目标方块（G），过程中可以经过安全方块（F），但需要避免进入危险方块（H）。智能体每一步都可以选择上下左右其中一个方向前进，但有一定概率受到“风”的影响，导致随机前进到一个方块。因此，不可能每次都完成最优的出行，但学习如何安全到达安全方块是可行的。在该环境中，每一步前进的奖赏都是0，唯有到达目标方块后获得奖赏1。\n",
    "\n",
    "Frozen Lake可以说是一个最基础的强化学习体验案例，因为它的起始状态与终止状态都固定，且状态空间（一维16个取值）与动作空间（一维4个取值：上/下/左/右）足够小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的Q-Learning实现方式是构造一个记录状态-动作对价值的表格（Q-Table）。在该表格中，每行代表一个状态，每列代表一个动作。在Frozen Lake这个案例中，Q-Table大小是16\\*4，即需要学习出16\\*4个状态-动作对的价值，最后根据这些价值选择合适的动作。首先，需要将Q-Table所有值初始化为0，然后根据智能体在该环境的经历，不断更新Q-Table的各个值。采用经典的[Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation) 去更新表格：以下是基于Q-Table的Q-Learning实现：\n",
    "\n",
    "**Eq(1)**: $ Q(s,a)=r+\\lambda (\\mathop {\\max }\\limits_{a'} (Q(s',a')))$\n",
    "\n",
    "其中，\n",
    "$Q(s,a)$表示状态-动作对（s，a）的收益；r表示在状态s执行动作a的即时奖赏；$Q(s',a')$ 表示在状态s执行动作a后到达下一状态的收益；$\\lambda$是折扣系数，允许我们确定当前奖赏和未来收益之间的重要性。上式说明的是，**当前状态-动作对（s，a）的期望收益等于当前获得的奖赏加上最好的长期效益**。这种更新方法使得每一次更新都重新使用了之前的更新结果，是一个迭代的过程。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.67500456e-04 9.78456330e-02 2.72223444e-04 3.37446997e-04]\n",
      " [1.04062086e-05 1.66738822e-05 1.81889254e-05 4.49573617e-02]\n",
      " [2.03219302e-05 1.18330181e-04 2.43686809e-05 1.18771185e-02]\n",
      " [1.21114558e-05 1.37007786e-05 7.37863675e-06 2.99169155e-03]\n",
      " [1.12936257e-01 7.53579829e-05 5.56291827e-05 2.27711092e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.26176016e-07 2.80480342e-08 1.01975389e-02 3.15001685e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.71615877e-06 6.17120549e-05 3.50345412e-05 1.17501844e-01]\n",
      " [6.05794953e-05 4.85933341e-01 3.14152940e-05 3.00864925e-05]\n",
      " [6.40997119e-02 3.92317816e-06 1.52894792e-07 4.17809373e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.84368982e-05 0.00000000e+00 9.98625765e-02 1.20424407e-03]\n",
      " [0.00000000e+00 0.00000000e+00 9.63185330e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Qt = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "\n",
    "lr = 0.9\n",
    "lam = 0.95\n",
    "num_episodes = 50000\n",
    "rAlllist=[]\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    j = 0\n",
    "    max_steps_in_episode = 99\n",
    "    rAll=0.\n",
    "    \n",
    "    while j<max_steps_in_episode:\n",
    "        # action[0:Left ## 1:Down ## 2:Right ## 3:Up]\n",
    "        if i<48000:\n",
    "            a = np.argmax(Qt[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        else:\n",
    "            a = np.argmax(Qt[s,:])\n",
    "        s_next, r, d,_ = env.step(a)\n",
    "        Qt[s,a] = Qt[s,a] + lr*(r+lam*np.max(Qt[s_next,:])-Qt[s,a])\n",
    "        s = s_next\n",
    "        rAll+=r\n",
    "        if d==True:\n",
    "            break\n",
    "        j+=1\n",
    "    rAlllist.append(rAll/j)\n",
    "    \n",
    "print(Qt)\n",
    "plt.figure(1)\n",
    "plt.plot(rAlllist)\n",
    "plt.figure(2)\n",
    "plt.title('Q Table')       \n",
    "plt.xticks(np.arange(0,env.action_space.n,1.0))\n",
    "plt.yticks(np.arange(0,env.observation_space.n,1.0))\n",
    "plt.imshow(Qt, interpolation='none',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.clim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67. 57. 55. 39.]\n",
      " [70.  0. 36.  0.]\n",
      " [72. 73. 35.  0.]\n",
      " [ 0. 74. 76. 77.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x285 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "s = env.reset()\n",
    "route=np.zeros([4,4])\n",
    "if s_next<4:\n",
    "    i=0\n",
    "    j=s_next\n",
    "else:\n",
    "    i = int(s_next/4)\n",
    "    j = s_next%4\n",
    "route[i,j]=1\n",
    "step=1\n",
    "d=False\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "# 在线绘制agent移动路线\n",
    "while d==False:\n",
    "    ax.clear()\n",
    "    plt.xticks(np.arange(0,4,1.0))\n",
    "    plt.yticks(np.arange(0,4,1.0))\n",
    "    ax.imshow(route, interpolation='none',aspect='auto')\n",
    "    fig.canvas.draw()\n",
    "    plt.pause(0.3)\n",
    "    a = np.argmax(Qt[s,:])\n",
    "    s_next, r, d,_ = env.step(a)\n",
    "    step+=1\n",
    "    if s_next<4:\n",
    "        i=0\n",
    "        j=s_next\n",
    "    else:\n",
    "        i = int(s_next/4)\n",
    "        j = s_next%4\n",
    "    route[i,j]=step\n",
    "    s = s_next\n",
    "\n",
    "print(route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 基于Q-Network的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很容易可以想到：当状态空间和动作空间非常大时，Q-Table往往要求庞大的存储空间，且不够灵活，为了降低存储消耗，我们可以通过构造一个函数去估计Q-Table，神经网络是一个常见且有效的选择，利用神经网络去充当估计器，我们可以通过构造（特征）向量表示任意状态，生成神经网络的输入，然后让网络学习状态对应的效益值。\n",
    "\n",
    "在本小节的案例中，我们可以通过one-hot向量去描述(输入)状态：: $s\\in R^{1x16}$,而对应的输出则是该状态下，执行每个可选动作的效益值：$Q\\in R^{1x4}$。在神经网络中，我们通过梯度下降优化损失函数的方式进行“Q-Table”的更新学习，对应的损失函数为：\n",
    "\n",
    "**Eq(2)**: $Loss=\\sum (Q_{target}-Q_{estimate})^2$\n",
    "\n",
    "$Q_{target}=r+\\lambda (\\mathop {\\max }\\limits_{a'} (Q_{estimate}(s',a'))))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上，在处理FrozenLake问题时，神经网络并不比Q-Table方法来的多高效。同时需要指出，尽管利用神经网络拟合Q值为描述Q值带来了更大的灵活性，但该方法在进行Q-Learning时稳定性不佳，收敛花费时间较长。当下有大量基于神经网络进行Q-Learning的扩展研究，目的就是为了寻求一个更好更稳定的Q值估计结果，在这些研究中，尤为著名的是[Atari-playing Deep Q-Networks](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)中提出的**Experience Replay**和**冻结目标网络** ："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience Replay**\n",
    "\n",
    "在智能体与环境交互时，存储每次的经历$<s,a,r,s'>$，存储点记为replay memory。在训练Q神经网络时，在replay memory中随机采样出经历，而非使用最近的经历。这样的做法可以打破每批训练样本的相似性，以免网络过早陷入局部最优。同时，Experience Replay的使用让学习过程与一般的监督学习更为相似，这也一定程度简化了算法的调试流程，特别地，我们甚至可以人工收集经历，然后再让智能体学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**冻结目标网络**\n",
    "\n",
    "在公式2中，损失函数中的目标值$Q_{target}=r+\\lambda (\\mathop {\\max }\\limits_{a'} (Q_{estimate}(s',a'))))$需要估计，冻结目标网络实质上是通过构造一个与原训练神经网络构造完全一样的“目标网络”去完成这个估计。具体来说，每当原训练神经网络的参数更新了一段时间，我们就将该套参数加载到“目标网络”，在更新原训练神经网络时，用“目标网络”去估计目标值。这一做法相比于传统的在线Q-Learnig会使训练更加稳定，因为在以往的在线Q-Learning中，网络更新会立即影响$Q_{target}$，很可能会导致策略的振荡甚至发散，冻结目标网络使得目标值的估计可以稳定一段时间，使得策略学习更不易发散。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-Network Approach in Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.5)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.02, shape=shape)\n",
    "    return initial\n",
    "\n",
    "state_dim_ = env.observation_space.n\n",
    "action_dim_ = env.action_space.n\n",
    "\n",
    "class DQN():\n",
    "    def __init__(self, sess, state_dim, action_dim=1, lamda=0.95, updateStep=10, output_num=4):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.state = tf.placeholder(tf.float32,[None,self.state_dim],name='state')\n",
    "        self.next_state = tf.placeholder(tf.float32,[None,self.state_dim],name='next_state')\n",
    "        self.action = tf.placeholder(tf.float32,[None,self.action_dim],name='state')\n",
    "        self.reward = tf.placeholder(tf.float32,[None, 1], name='reward')\n",
    "        self.lamda = lamda\n",
    "        self.updateStep = updateStep\n",
    "        self.output_num = output_num\n",
    "        self.sess = sess\n",
    "    \n",
    "    def buildQNetwork(self,):\n",
    "        \n",
    "        with tf.variable_scope('update-Qnetwork'):\n",
    "            w1 = weight_variable([self.state_dim,self.output_num])\n",
    "            b1 = bias_variable([self.output_num])\n",
    "            \n",
    "        with tf.variable_scope('target-Qnetwork'):\n",
    "            w1_ = weight_variable([self.state_dim,self.output_num])\n",
    "            b1_ = bias_variable([self.output_num])\n",
    "                                \n",
    "        self.e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='update-Qnetwork')\n",
    "        self.t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target-Qnetwork')\n",
    "                                \n",
    "        self.Qset = tf.nn.elu(tf.matmul(self.state, w1)+b1)\n",
    "        self.targetQset = tf.nn.elu(tf.matmul(self.next_state, w1_)+b1_)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.squared_difference(self.reward+self.targetQset*self.lamda, self.Qset))\n",
    "        self.a = tf.argmax(self.Qset,1)\n",
    "        \n",
    "        self.trainOp = tf.train.AdamOptimizer(learning_rate=0.01).minimize(self.loss)\n",
    "    \n",
    "    def learn(self,step,memory):#stateBacth, actionBatch, rewardBatch, nextStateBatch\n",
    "        \n",
    "        _, loss = self.sess.run([self.trainOp,self.loss], feed_dict={self.state : memory[:,0:self.state_dim], self.action : memory[:,self.state_dim].reshape(-1,1),\n",
    "                                              self.reward : memory[:,self.state_dim+1].reshape(-1,1), self.next_state : memory[:,-self.state_dim:]})\n",
    "        \n",
    "        if step%self.updateStep==0:\n",
    "            # update tar by (1.-0.01)*tar + 0.01*eva\n",
    "            self.sess.run([tf.assign(tar, (1.-0.01)*tar + 0.01*eva) for tar, eva in zip(self.t_params, self.e_params)])\n",
    "        return loss\n",
    "    \n",
    "    def choose_action(self,state):\n",
    "        return self.sess.run(self.a, feed_dict={self.state:state})\n",
    "        \n",
    "class replay_memory():\n",
    "    def __init__(self, memory_capacity, state_dim, action_dim=1):\n",
    "        self.memory_capacity = memory_capacity\n",
    "        self.memory = np.zeros((self.memory_capacity, 2*state_dim+action_dim+1))  \n",
    "        self.pointer = 0\n",
    "        \n",
    "    def store_experience(self, state, action, reward, next_sate):\n",
    "        index = self.pointer%self.memory_capacity\n",
    "        experience  = np.hstack((state, action, reward, next_sate))\n",
    "        self.memory[index,:]=experience\n",
    "        self.pointer+=1\n",
    "        \n",
    "    def replay(self,batch_size):\n",
    "        memory_batch = []\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.randint(0,self.memory_capacity)\n",
    "            memory_batch.append(self.memory[index,:])\n",
    "        return memory_batch        \n",
    "    \n",
    "    \n",
    "tf.reset_default_graph()\n",
    "sess_ = tf.Session()\n",
    "model = DQN(state_dim=state_dim_, lamda=0.95,updateStep=10, sess=sess_)\n",
    "model.buildQNetwork()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess_.run(init_op)\n",
    "\n",
    "M = replay_memory(memory_capacity=128, state_dim=state_dim_)\n",
    "batch_size_ = 32\n",
    "num_episodes = 500\n",
    "\n",
    "records = 0\n",
    "loss_set=[]\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    j = 0\n",
    "    max_steps_in_episode = 99\n",
    "    while j<max_steps_in_episode:\n",
    "        state_vector = np.zeros([1,state_dim_])\n",
    "        nextSate_vector = np.zeros([1,state_dim_])\n",
    "        state_vector[0,s]=1\n",
    "        a = model.choose_action(state=state_vector)\n",
    "        s_next, r, d,_ = env.step(a[0])\n",
    "        nextSate_vector[0,s_next]=1\n",
    "        \n",
    "        reward=np.array(r).reshape(1,1)\n",
    "        \n",
    "        M.store_experience(state=state_vector, action=np.array(a).reshape(1,1), reward=np.array(r).reshape(1,1), next_sate=nextSate_vector)\n",
    "        \n",
    "        j+=1\n",
    "        records+=1\n",
    "        \n",
    "        if records>M.memory_capacity:\n",
    "            memory_batch = M.replay(batch_size=batch_size_)\n",
    "            loss_ = model.learn(records,memory=np.array(memory_batch) )\n",
    "            loss_set.append(loss_)\n",
    "        if d==True:\n",
    "            break\n",
    "\n",
    "plt.plot(loss_set)\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2373638   0.17330158 -0.13279152 -0.21077365]\n",
      " [ 0.3162412  -0.04182023 -0.62010187 -0.32224095]\n",
      " [ 0.07921799 -0.29625273 -0.16530985 -0.2556535 ]\n",
      " [ 0.20199314  0.0346947  -0.44751608  0.17124237]\n",
      " [ 0.46219882  0.26055557 -0.40123969 -0.07045317]\n",
      " [ 0.4294745   0.36401945 -0.26201755  0.12366693]\n",
      " [ 0.35229126  0.38378638 -0.54476321 -0.21351653]\n",
      " [-0.00852311 -0.24345529  0.55759662 -0.50474918]\n",
      " [ 0.03486028  0.51303446  0.91330451 -0.46845514]\n",
      " [ 0.36114416  0.3814961   0.00761066 -0.1062001 ]\n",
      " [ 0.31450063 -0.12834334  0.24177049 -0.18782645]\n",
      " [ 0.39869243  0.71143323 -0.42219681 -0.39107198]\n",
      " [ 0.16276333  0.47621256  0.0735338   0.17801365]\n",
      " [ 0.37008095 -0.54096818  0.35454586 -0.03328127]\n",
      " [ 0.44521427 -0.21963626  0.83468562 -0.24551922]\n",
      " [ 0.47466582 -0.47779852  0.43994406  0.90818107]]\n"
     ]
    }
   ],
   "source": [
    "Qtable=np.zeros((state_dim_, action_dim_))\n",
    "for i in range(state_dim_):\n",
    "    state_vector=np.zeros([1,state_dim_])\n",
    "    state_vector[0,i] = 1\n",
    "    Q_ = sess_.run(model.Qset, feed_dict={model.state:state_vector})\n",
    "    Qtable[i,:]=np.array(Q_[0])\n",
    "\n",
    "print(Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.  0.]\n",
      " [13.  0.  0.  0.]\n",
      " [16. 15.  0.  0.]\n",
      " [17.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "s = env.reset()\n",
    "route=np.zeros([4,4])\n",
    "if s_next<4:\n",
    "    i=0\n",
    "    j=s_next\n",
    "else:\n",
    "    i = int(s_next/4)\n",
    "    j = s_next%4\n",
    "route[i,j]=1\n",
    "step=1\n",
    "d=False\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "# 在线绘制agent移动路线\n",
    "while d==False:\n",
    "    ax.clear()\n",
    "    plt.xticks(np.arange(0,4,1.0))\n",
    "    plt.yticks(np.arange(0,4,1.0))\n",
    "    ax.imshow(route, interpolation='none',aspect='auto')\n",
    "    fig.canvas.draw()\n",
    "    plt.pause(0.3)\n",
    "    \n",
    "    state_vector=np.zeros([1,state_dim_])\n",
    "    state_vector[0,s] = 1\n",
    "    a = sess_.run(model.a, feed_dict={model.state:state_vector})\n",
    "    s_next, r, d,_ = env.step(a[0])\n",
    "    step+=1\n",
    "    if s_next<4:\n",
    "        i=0\n",
    "        j=s_next\n",
    "    else:\n",
    "        i = int(s_next/4)\n",
    "        j = s_next%4\n",
    "    route[i,j]=step\n",
    "    s = s_next\n",
    "\n",
    "print(route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1][Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)\n",
    "\n",
    "[2][DEMYSTIFYING DEEP REINFORCEMENT LEARNING](https://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/)\n",
    "\n",
    "[3][Convergence of Q-Learning: a simple proof](http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Policy-based Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Two-armed Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "强化学习使得我们不仅得以教一个智能体如何工作，并允许智能体通过与环境的交互自行学习如何工作。深度神经网络借助目的导向学习的智能体，可以学习到复杂的环境表达信息，结合学习到的表达，计算机取得了一些令人惊叹的成就，包括[在Atari games上击败人类](https://deepmind.com/research/dqn/)以及[击败围棋冠军](https://deepmind.com/research/alphago/)。\n",
    "\n",
    "学习如何构造这些智能体要求我们从监督学习的工作思路中转变过来。那种找个算法去匹配某些确定刺激和其响应的能力已经不再靠谱了，相反，强化学习算法必须能够使智能体基于“环境状态”，“即时奖赏”以及“动作”这几个元素，自主去获取并学习到合适的输入输出关系。此时，现在无论在何种场景，我们不再能告诉智能体理应执行的所谓的正确的行为，因此，问题相对更加复杂。\n",
    "\n",
    "本小节将以新的一个小问题来探索强化学习——n-armed bandit，也就是n个摇杆的老虎机，每个摇杆都对应固定的选择几率。这个游戏的目标是摸索出这个老虎机最优的摇杆选择几率组合，即一种投币策略，来最大化每次执行该策略获取的奖赏。现在我们先进一步简化这个问题，研究对象选为一个两个摇杆的老虎机。事实上，这个简化后的问题也太简单了，就姑且将它视为更多是一个解决实际强化学习问题的探路者。\n",
    "\n",
    "需要强调的是，被视为强化学习问题的任务会具备以下典型的特点：\n",
    "\n",
    "- 不同的动作决策对应不同的即时奖赏。打个比方，当在一个迷宫寻宝时，在某个位置向右走得到宝藏，向左走遇见陷阱。\n",
    "\n",
    "- 考虑奖赏的前瞻性。即考虑将来可能发生的奖赏，在我们到达向右走就可以得到宝藏的位置前，我们应首先认识到走到该位置是诱人的。\n",
    "\n",
    "- 动作决策的奖赏是基于所处的状态的。在某个位置执行的动作，获取了好的奖赏，在另一个位置执行相同的动作却不一定同样获得好的回报。\n",
    "\n",
    "此次的案例是一个非常简单的开始，它不考虑所处的状态（每次都一样），也不考虑长远收益（前后两个动作相互独立），即忽略了后两个要素。我们需要关注的仅仅是去认识每个动作对应的可能的奖赏，并学习如何去最大化获得的奖赏，如何实现这个目标以强化学习的术语来表达就是策略（policy）——现在我们关注policy-based agent，相比于Q-Learning **“环境$\\rightarrow$Q value$\\rightarrow$动作”**的工作模式，现在的思路是**“环境$\\rightarrow$动作”**，也根据就是直接学习环境到动作的映射。这里用到的优化算法是[policy gradient](http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)：构造接受环境状态输入，输出动作的神经网络作为决策单元，通过智能体与环境的交互推导出优化神经网络权重的梯度，进行权重的更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本小节主要参考Sutton等人的著作，将从比较数学的角度捋一遍policy gradient：\n",
    "\n",
    "将根据状态选择动作的策略参数化：\n",
    "\n",
    "**Eq(3)**:$\\pi(a|s,\\theta)=Pr\\{A_t=a|S_t=s,\\theta_{t}=\\theta\\}$\n",
    "\n",
    "基于参数化策略，可以定义某策略下，从任意一个状态$s$出发执行策略的期望效益为：\n",
    "\n",
    "**Eq(4)**：$J(\\theta)\\dot{=}v_{\\pi}(s)=\\sum\\limits_{s\\in S}\\mathop {\\sum }\\limits_{a}\\pi(a|s,\\theta)Q_{\\pi}(s,a)$\n",
    "\n",
    "其中，$\\mu{(s)}= \\sum\\limits_{k=0}^{\\infty}\\gamma^{k} Pr(s \\rightarrow x,k,\\pi)$考虑了从状态$s$出发到任意一个状态$x$的概率及经历的期望步数$k$，表达从状态$s$出发到任意一个状态$x$的的期望折扣。\n",
    "\n",
    "很自然可以想到用梯度上升的方式优化上式，需要指出的是，策略参数的更新梯度通过执行的动作和对应的奖赏可以比较直截了当地获得，但执行的策略导致的状态转移是基于所处环境的一个未知表达，因此无法计算这方面作用的梯度，幸运的是，Sutton等人已经证明策略的更新梯度计算不需要考虑状态转移函数的梯度，得出简洁的策略梯度定理：\n",
    "\n",
    "> **Eq(5)**:$\\bigtriangledown J(\\theta) \\propto \\mathop {\\sum }\\limits_{s}\\mu{(s)}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)Q_{\\pi}(s,a)$\n",
    ",$\\mu{(s)}= \\sum\\limits_{k=0}^{\\infty}\\gamma^{k} Pr(s \\rightarrow x,k,\\pi)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforce\n",
    "\n",
    "\n",
    "把**Eq(5)**视为基于策略$\\pi$的期望：\n",
    "\n",
    "$ \\mathop {\\sum }\\limits_{s}\\mu{(s)}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)Q_{\\pi}(s,a)=E_{\\pi}[\\gamma^{k}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)Q_{\\pi}(s,a)]$\n",
    "\n",
    "简单的变形：\n",
    "\n",
    "$E_{\\pi}[\\gamma^{k}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)Q_{\\pi}(s,a)]=E_{\\pi}[\\gamma^{k}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)Q_{\\pi}(s,a)\\frac{\\pi(a|s,\\theta)}{\\pi(a|s,\\theta)}]=E_{\\pi}[\\gamma^{k}\\mathop {\\sum }\\limits_{a}\\bigtriangledown log \\pi(a|s,\\theta)Q_{\\pi}(s,a) {\\pi(a|s,\\theta)} ]$\n",
    "\n",
    "由于动作$a$来源于策略$\\pi$,既有$A_{t}~\\pi$，将动作与状态都视为随机变量，此时上述期望进一步化解：\n",
    "\n",
    "**Eq(6)**：$\\bigtriangledown J(\\theta)=E_{\\pi}[\\gamma^{k} \\bigtriangledown log \\pi(A_t|S_t,\\theta)Q_{\\pi}(S_t,A_t)]$\n",
    "\n",
    "以上即基于策略梯度定理的Reinforce算法，算是策略梯度一类方法的鼻祖，它基于MC的方法进行采样计算梯度，可以看到，为了得到$Q(S_t,A_t)$，每次的MC都需要经历一个完整的episode，故Reinforce只能用于finite-episode的场景，且效率较低，训练方差较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforce with Baseline\n",
    "\n",
    "在**Eq(6)**中，为了减少梯度的方差，使得训练更加平稳，让效益值减去baseline使得每次效益值尽可能固定：\n",
    "\n",
    "$E_{\\pi}[\\gamma^{k}\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)(Q_{\\pi}(s,a)-b(s))]$\n",
    "\n",
    "由于$E_{\\pi}[\\gamma^{k} \\bigtriangledown \\pi(A_t|S_t,\\theta)b(S_t)]=\\mathop {\\sum }\\limits_{a}\\bigtriangledown \\pi(a|s,\\theta)b(s)=b(s)\\bigtriangledown 1=0$，因此这个trick保证了训练稳定性的同时，并不影响梯度的计算。这是Reinforce的一种改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actor-Critic\n",
    "\n",
    "那么，baseline $b(s)$怎么选才靠谱呢？还有，是否可以让每次的梯度计算不需要完整经历一个episode才进行？Actor-Critic方法就是Reinforce回答这两个问题后的升级版本：\n",
    "\n",
    "即令$b(s)=Q_{estimate}(s,a)$,同时引入TD-difference的更新机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A naive trial : Multi-armed bandit with policy gradient in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-cb6f9c76a953>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-cb6f9c76a953>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# 最简单版本的策略梯度案例\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "bandits = [0.2,0,-0.2,-5]\n",
    "\n",
    "def pullBandit(bandit):\n",
    "    result = np.random.randn(1)\n",
    "    if result>bandit:\n",
    "        return 1 # positive reward\n",
    "    else: return -1\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.5)\n",
    "    return tf.Variable(initial)\n",
    "    \n",
    "class agent():\n",
    "    def __init__(self,):\n",
    "        self.action = tf.placeholder(tf.float32,[None,1])\n",
    "        self.reward = tf.placeholder(tf.float32,[None,1])\n",
    "    def buildPolicyNetwork(self,):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [Simple Reinforcement Learning in Tensorflow: Part 1 - Two-armed Bandit](https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149)\n",
    "\n",
    "[2][Simple Reinforcement Learning with Tensorflow Part 1.5: Contextual Bandits](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-1-5-contextual-bandits-bff01d1aad9c)\n",
    "\n",
    "[3][Simple Reinforcement Learning with Tensorflow: Part 2 - Policy-based Agents](https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-2-ded33892c724)\n",
    "\n",
    "[4]Sutton R S, Barto A G. Reinforcement learning: An introduction[M]. MIT press, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
